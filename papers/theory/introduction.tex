\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, hyperref}
\usepackage{amsthm}
\usepackage{geometry}
\usepackage[backend=biber]{biblatex}
\addbibresource{../references.bib}
\newtheorem{lemma}{Lemma}
\geometry{margin=1in}
\title{\LARGE The Abstract Universe Project}
\author{Juha Meskanen}
\date{2019 -- \today}

\begin{document}

\maketitle

\section{Introduction}

Physics has long grappled with the apparent disjunction between quantum mechanics and general relativity. While the former describes the probabilistic behavior of subatomic particles, the latter governs the smooth, deterministic curvature of spacetime. Unifying these frameworks has proven notoriously difficult, particularly due to the fundamentally different assumptions about locality, determinism, and measurement.

As intelligent observers embedded in the universe, we attempt to model the very system we are part of. This raises foundational limits reminiscent of Gödel's incompleteness theorem: just as no sufficiently powerful formal system can prove all truths about itself, perhaps no internal observer can derive a complete physical theory of the universe from within \cite{dyson2004godel}. These self-referential limits motivate the search for a new foundation grounded not in geometry or fields, but in information.

In this work, we reject the presumption that spacetime or particles are ontologically fundamental \cite{wheeler1990it} \citation{zuse1970calculating}. We show that the universe is made of abstract information, provided only four observable assumptions hold. Spacetime and particles must then be emergent properties arising from information \cite{zuse1970calculating} \cite{tegmark2008mathematical}. Our goal is to develop a framework in which everything we perceive—including geometry, matter, time, and even consciousness—can be derived from information.

\section{Four Observational Assumptions}

We begin with four assumptions that are not metaphysical postulates, but observationally grounded regularities evident in both physics and computation. These assumptions are minimal, falsifiable, and intentionally free of ontological commitments. From them, we derive a striking conclusion: the universe must be fundamentally informational, and all informational states that satisfy these assumptions already exist.

This line of reasoning lead us to reinterpret all physical features as emergent informational phenomena.  The framework developed assumes no primitive physical substrate—no predefined spacetime, particles, or fields. Everything we observe, from matter to consciousness, is modeled as an emergent structure within a fundamentally informational universe.



\section*{The Observer Prevalence Principle}

Let $n$ be a fixed number of bits. Let $\mathcal{U}_n = \{0,1\}^n$ denote the set of all $2^n$ binary strings, interpreted as candidate universes. Let $\mathcal{O}_n = \{0,1\}^n$ denote the same set, interpreted as candidate observers.

Define a \textbf{compatibility function}
\[
      \mathrm{Compat}: \mathcal{O}_n \times \mathcal{U}_n \rightarrow \{0,1\}
\]
such that $\mathrm{Compat}(o, u) = 1$ if observer $o$ can exist within universe $u$ under a chosen observer model (e.g., memory encoding, trajectory embedding, structural motif match), and 0 otherwise.

\begin{definition}[Observer Prevalence Principle]
      The \emph{subjective probability} that a given observer $o \in \mathcal{O}_n$ experiences a particular universe $u \in \mathcal{U}_n$ is proportional to the number of universes compatible with $o$:
      \[
            \Pr(u \mid o) \propto \mathrm{Compat}(o, u).
      \]
      Equivalently, the most probable universe an observer experiences is the one maximizing the number of observer-compatible instances:
      \[
            u^* = \arg\max_{u \in \mathcal{U}_n} \sum_{o \in \mathcal{O}_n} \mathrm{Compat}(o, u).
      \]
\end{definition}

This principle implies that the observed universe is biased toward configurations that support the maximal number of observers isomorphic to the subject, leading to emergent regularities (e.g., smooth physical laws, coherent time evolution) that favor observer persistence.

\begin{remark}
      The special case where an observer $o$ is identical to a universe $u$ (i.e., $o = u$ and $\mathrm{Compat}(o, u) = 1$ trivially) defines a fixed point of maximal internal consistency. This limiting case represents an informational singularity—an observer-universe with no internal entropy or external reference.
\end{remark}



\section*{A Technical Introduction to an Observer-Centric, Information-Theoretic Theory of Everything}

This theory proposes that \textbf{physical reality emerges from pure information}, with no need to assume pre-existing spacetime, particles, or energy. At the center is the following hypothesis:

\begin{quote}
      \textit{The most probable universe is the one that minimizes the informational description of the observer.}
\end{quote}

The universe is modeled as a set of finite-length bitstrings evolving over discrete time steps. Observers are defined as memory-encoded patterns within those bitstrings. A universe is said to implement an observer if it contains a coherent embedding of the observer’s memory across time. Among all such universes, \textbf{those with minimal total description length} — i.e., those offering the best data compression of the observer — are statistically favored.

\subsection*{1. Observer-Centric Selection Principle}

The observer is not external to the universe but embedded within it. For a bitstring universe $U$, and an observer pattern $O$, we define the compatibility function $C(U, O)$ based on:

\begin{itemize}
      \item \textbf{Memory embedding}: The observer must find a consistent sequence of memory states in $U$.
      \item \textbf{Compression}: The joint configuration of $U$ and $O$ should have minimal Kolmogorov complexity.
\end{itemize}

Formally, we define the observer-weighted universe probability as:
\[
      P(U \mid O) \propto 2^{-K(U \mid O)}
\]
where $K(U \mid O)$ is the conditional Kolmogorov complexity of the universe given the observer. Universes with more regularity — i.e., more easily expressed using fewer bits — dominate the ensemble.

\subsection*{2. Wavefunction as Compression Algorithm}

A central insight of the theory is that the \textbf{wavefunction is not a physical field}, but a compression scheme — a compact encoding of possible observer-consistent universes. Sinusoidal patterns, being maximally compressible via Fourier bases, naturally dominate. This yields a statistical bias toward universes that exhibit \textbf{wave-like evolution}, which in turn gives rise to quantum interference, superposition, and smooth particle trajectories.

\subsection*{3. Time, Entropy, and the Observer's Horizon}

Time is modeled as an ordered super-set of bitstrings. Past states are constrained by observer memory; future states are undetermined but \textbf{filtered} through the compression mechanism (the wavefunction), yielding a \textbf{probabilistic projection} rather than deterministic evolution.

\begin{itemize}
      \item The \textbf{past} is the region of high similarity with observer memory.
      \item The \textbf{future} is a superposition of all possible continuations consistent with the observer’s wavefunction.
\end{itemize}

This leads to an asymmetric structure: \textbf{a classical past and a quantum mechanical future}, unified through entropy and informational symmetry.

\subsection*{4. Physical Laws as Emergent Regularities}

No physical constants are assumed. Instead, \textbf{laws of physics emerge as statistical biases} in the set of observer-compatible universes. For example:

\begin{itemize}
      \item \textbf{Particles}: Recurring spatial motifs across frames.
      \item \textbf{Fields}: Gradients in compressed observer-compatible configurations.
      \item \textbf{Gravity}: Emerges from local entropy gradients that attract compatible observer trajectories.
\end{itemize}

All such phenomena arise not from axioms of physics, but from the mathematics of information compression and observer self-location.

\subsection*{5. Simulation and Empirical Grounding}

A concrete implementation of this theory samples all possible spacetime bitstring paths of a given size and ranks them by wave-based compression with respect to an observer pattern. High-scoring paths exhibit:

\begin{itemize}
      \item Increasing entropy over time (arrow of time)
      \item Emergent particle-like structures
      \item Smooth geodesic-like motion
      \item Quantum-like predictive uncertainty and interference
\end{itemize}


\subsection*{Conclusion}

This theory redefines ontology: \textbf{reality is not made of matter but of compressible information}, with observers acting as statistical filters. The universe is not a singular entity but a probabilistic ensemble weighted by informational efficiency. And physics — all of it — is just the echo of a deeper algorithm: \textbf{find the wave that best describes you.}



\end{document}

